#!/usr/bin/env python3
"""
AIãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
X API Basic ($200/æœˆ) ã«åã¾ã‚‹ã‚ˆã†è¨­è¨ˆ
"""

import os
import json
import yaml
import requests
import feedparser
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import time


@dataclass
class Item:
    """åé›†ã—ãŸæƒ…å ±ã‚¢ã‚¤ãƒ†ãƒ """
    source: str  # "x_account", "x_search", "rss", "github"
    title: str
    url: str
    published_at: str
    score: int = 0
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class StateManager:
    """çŠ¶æ…‹ç®¡ç†ï¼ˆstate.jsonï¼‰"""

    def __init__(self, state_path: str = "data/state.json"):
        self.state_path = state_path
        self.state = self._load()

    def _load(self) -> Dict:
        """state.json ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.state_path):
            with open(self.state_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            "x_accounts": {},
            "x_keywords": {},
            "rss": {},
            "github": {},
            "meta": {"last_run_at": None, "version": "1.0.0"}
        }

    def save(self):
        """state.json ã‚’ä¿å­˜"""
        self.state["meta"]["last_run_at"] = datetime.now(timezone.utc).isoformat()
        with open(self.state_path, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def get_x_account_since_id(self, username: str) -> Optional[str]:
        """Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆã® since_id ã‚’å–å¾—"""
        return self.state["x_accounts"].get(username, {}).get("since_id")

    def set_x_account_since_id(self, username: str, user_id: str, since_id: str):
        """Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆã® since_id ã‚’æ›´æ–°"""
        if username not in self.state["x_accounts"]:
            self.state["x_accounts"][username] = {}
        self.state["x_accounts"][username]["user_id"] = user_id
        self.state["x_accounts"][username]["since_id"] = since_id

    def get_x_keyword_since_id(self, keyword: str) -> Optional[str]:
        """Xã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã® since_id ã‚’å–å¾—"""
        return self.state["x_keywords"].get(keyword, {}).get("since_id")

    def set_x_keyword_since_id(self, keyword: str, since_id: str):
        """Xã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã® since_id ã‚’æ›´æ–°"""
        if keyword not in self.state["x_keywords"]:
            self.state["x_keywords"][keyword] = {}
        self.state["x_keywords"][keyword]["since_id"] = since_id

    def get_rss_last_published(self, feed_url: str) -> Optional[str]:
        """RSSã®æœ€çµ‚å–å¾—æ—¥æ™‚ã‚’å–å¾—"""
        return self.state["rss"].get(feed_url)

    def set_rss_last_published(self, feed_url: str, published_at: str):
        """RSSã®æœ€çµ‚å–å¾—æ—¥æ™‚ã‚’æ›´æ–°"""
        self.state["rss"][feed_url] = published_at

    def get_github_last_tag(self, repo: str) -> Optional[str]:
        """GitHubãƒªãƒã‚¸ãƒˆãƒªã®æœ€çµ‚tagã‚’å–å¾—"""
        return self.state["github"].get(repo, {}).get("tag")

    def set_github_last_tag(self, repo: str, tag: str):
        """GitHubãƒªãƒã‚¸ãƒˆãƒªã®æœ€çµ‚tagã‚’æ›´æ–°"""
        if repo not in self.state["github"]:
            self.state["github"][repo] = {}
        self.state["github"][repo]["tag"] = tag


class XAPIClient:
    """X (Twitter) API v2 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, bearer_token: str):
        self.bearer_token = bearer_token
        self.base_url = "https://api.twitter.com/2"
        self.headers = {"Authorization": f"Bearer {bearer_token}"}

    def get_user_id(self, username: str) -> Optional[str]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å–å¾—"""
        url = f"{self.base_url}/users/by/username/{username}"
        response = requests.get(url, headers=self.headers)
        if response.status_code == 200:
            data = response.json()
            return data.get("data", {}).get("id")
        return None

    def get_user_tweets(self, user_id: str, since_id: Optional[str] = None, max_results: int = 10) -> List[Dict]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆæ–°ç€ã®ã¿ï¼‰"""
        url = f"{self.base_url}/users/{user_id}/tweets"
        params = {
            "max_results": min(max_results, 100),
            "tweet.fields": "created_at,public_metrics",
            "expansions": "author_id"
        }
        if since_id:
            params["since_id"] = since_id
        else:
            # åˆå›å®Ÿè¡Œæ™‚ã¯ç›´è¿‘24æ™‚é–“
            start_time = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat()
            params["start_time"] = start_time

        response = requests.get(url, headers=self.headers, params=params)
        if response.status_code == 200:
            data = response.json()
            return data.get("data", [])
        return []

    def search_tweets(self, query: str, since_id: Optional[str] = None, max_results: int = 10) -> List[Dict]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ„ã‚¤ãƒ¼ãƒˆæ¤œç´¢ï¼ˆæ–°ç€ã®ã¿ï¼‰"""
        url = f"{self.base_url}/tweets/search/recent"
        params = {
            "query": query,
            "max_results": min(max_results, 100),
            "tweet.fields": "created_at,public_metrics",
            "expansions": "author_id"
        }
        if since_id:
            params["since_id"] = since_id
        else:
            # åˆå›å®Ÿè¡Œæ™‚ã¯ç›´è¿‘24æ™‚é–“
            start_time = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat()
            params["start_time"] = start_time

        response = requests.get(url, headers=self.headers, params=params)
        if response.status_code == 200:
            data = response.json()
            return data.get("data", [])
        return []


class DataCollector:
    """ãƒ‡ãƒ¼ã‚¿åé›†ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""

    # å„ªå…ˆåº¦ã®é«˜ã„RSSãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆé‡è¦ãƒ™ãƒ³ãƒ€ãƒ¼ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¼ã‚‰ã•ãªã„ãŸã‚ï¼‰
    PRIORITY_FEEDS = {
        # å…¬å¼ãƒ–ãƒ­ã‚°
        "https://www.anthropic.com/news/rss.xml": 1000,  # Anthropicæœ€å„ªå…ˆ
        "https://openai.com/blog/rss.xml": 1000,          # OpenAIæœ€å„ªå…ˆ
        "https://github.blog/feed/": 800,                 # GitHub Blog
        "https://code.visualstudio.com/updates/feed.xml": 800,  # VSCode Updates

        # GitHub Releases Atom Feed
        "https://github.com/anthropics/claude-code/releases.atom": 1000,  # Claude Codeæœ€å„ªå…ˆ
        "https://github.com/langchain-ai/langchain/releases.atom": 800,   # LangChain
        "https://github.com/openai/openai-python/releases.atom": 800,     # OpenAI Python SDK
        "https://github.com/run-llama/llama_index/releases.atom": 600,    # LlamaIndex
        "https://github.com/huggingface/transformers/releases.atom": 600, # Transformers
    }

    def __init__(self, config: Dict, state: StateManager, x_client: XAPIClient):
        self.config = config
        self.state = state
        self.x_client = x_client
        self.items: List[Item] = []
        self.stats = {
            "x_accounts_fetched": 0,
            "x_search_fetched": 0,
            "x_total_fetched": 0,
            "x_limit_reached": False,
            "rss_fetched": 0,
            "github_fetched": 0,
            "duplicates_removed": 0
        }

    def collect_all(self):
        """å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰åé›†"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹...")

        # X (Twitter)
        self._collect_x_accounts()
        self._collect_x_search()

        # RSSï¼ˆGitHub Releases Atom Feedã‚’å«ã‚€ï¼‰
        self._collect_rss()

        # é‡è¤‡æ’é™¤
        self._deduplicate()

        print(f"âœ… åé›†å®Œäº†: {len(self.items)} ä»¶")

    def _collect_x_accounts(self):
        """Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆåé›†"""
        accounts = self.config["x"]["accounts"]
        limit = self.config["x"]["limits"]["accounts"]
        fetched = 0

        print(f"ğŸ“± Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆç›£è¦–: {len(accounts)} ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")

        for username in accounts:
            if fetched >= limit:
                print(f"âš ï¸  ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç›£è¦–ã®ä¸Šé™ {limit} ä»¶ã«åˆ°é”")
                self.stats["x_limit_reached"] = True
                break

            user_id = self.x_client.get_user_id(username)
            if not user_id:
                continue

            since_id = self.state.get_x_account_since_id(username)
            tweets = self.x_client.get_user_tweets(user_id, since_id, max_results=10)

            if not tweets:
                continue

            # æœ€æ–°ã®tweet_idã‚’ä¿å­˜
            max_id = max(int(t["id"]) for t in tweets)
            self.state.set_x_account_since_id(username, user_id, str(max_id))

            for tweet in tweets:
                if fetched >= limit:
                    break

                item = Item(
                    source="x_account",
                    title=tweet["text"][:100],
                    url=f"https://twitter.com/{username}/status/{tweet['id']}",
                    published_at=tweet["created_at"],
                    score=self._calculate_engagement_score(tweet),
                    metadata={"username": username, "tweet": tweet}
                )
                self.items.append(item)
                fetched += 1

        self.stats["x_accounts_fetched"] = fetched
        self.stats["x_total_fetched"] += fetched

    def _collect_x_search(self):
        """Xã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"""
        keywords = self.config["x"]["keywords"]
        limit = self.config["x"]["limits"]["search"]
        fetched = 0

        print(f"ğŸ” Xã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {len(keywords)} ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")

        for keyword in keywords:
            if fetched >= limit:
                print(f"âš ï¸  æ¤œç´¢ã®ä¸Šé™ {limit} ä»¶ã«åˆ°é”")
                self.stats["x_limit_reached"] = True
                break

            since_id = self.state.get_x_keyword_since_id(keyword)
            tweets = self.x_client.search_tweets(keyword, since_id, max_results=10)

            if not tweets:
                continue

            # æœ€æ–°ã®tweet_idã‚’ä¿å­˜
            max_id = max(int(t["id"]) for t in tweets)
            self.state.set_x_keyword_since_id(keyword, str(max_id))

            for tweet in tweets:
                if fetched >= limit:
                    break

                item = Item(
                    source="x_search",
                    title=tweet["text"][:100],
                    url=f"https://twitter.com/i/web/status/{tweet['id']}",
                    published_at=tweet["created_at"],
                    score=self._calculate_engagement_score(tweet),
                    metadata={"keyword": keyword, "tweet": tweet}
                )
                self.items.append(item)
                fetched += 1

        self.stats["x_search_fetched"] = fetched
        self.stats["x_total_fetched"] += fetched

    def _collect_rss(self):
        """RSSåé›†"""
        feeds = self.config["rss"]["feeds"]
        fetched = 0

        print(f"ğŸ“° RSSåé›†: {len(feeds)} ãƒ•ã‚£ãƒ¼ãƒ‰")

        for feed_config in feeds:
            feed_url = feed_config["url"]
            feed_name = feed_config["name"]

            feed = feedparser.parse(feed_url)
            last_published = self.state.get_rss_last_published(feed_url)

            for entry in feed.entries:
                published = entry.get("published_parsed") or entry.get("updated_parsed")
                if not published:
                    continue

                published_dt = datetime(*published[:6], tzinfo=timezone.utc)
                published_iso = published_dt.isoformat()

                # æ–°ç€ã®ã¿
                if last_published and published_iso <= last_published:
                    continue

                # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: åŸºæœ¬ã‚¹ã‚³ã‚¢ + å„ªå…ˆåº¦ãƒœãƒ¼ãƒŠã‚¹
                base_score = self.config["slack"]["scoring"]["rss_bonus"]  # 500
                priority_bonus = self.PRIORITY_FEEDS.get(feed_url, 0)
                final_score = base_score + priority_bonus

                item = Item(
                    source="rss",
                    title=entry.title,
                    url=entry.link,
                    published_at=published_iso,
                    score=final_score,  # é‡è¦ãƒ•ã‚£ãƒ¼ãƒ‰: Anthropic/OpenAI=1500ç‚¹ã€GitHub/VSCode=1300ç‚¹ã€ãã®ä»–=500ç‚¹
                    metadata={"feed_name": feed_name, "feed_url": feed_url}
                )
                self.items.append(item)
                fetched += 1

            # æœ€æ–°ã® published_at ã‚’ä¿å­˜
            if feed.entries:
                latest = max(feed.entries, key=lambda e: e.get("published_parsed") or e.get("updated_parsed"))
                published = latest.get("published_parsed") or latest.get("updated_parsed")
                if published:
                    published_dt = datetime(*published[:6], tzinfo=timezone.utc)
                    self.state.set_rss_last_published(feed_url, published_dt.isoformat())

        self.stats["rss_fetched"] = fetched

    def _calculate_engagement_score(self, tweet: Dict) -> int:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—"""
        metrics = tweet.get("public_metrics", {})
        scoring = self.config["slack"]["scoring"]

        score = (
            metrics.get("like_count", 0) * scoring["like_weight"] +
            metrics.get("retweet_count", 0) * scoring["retweet_weight"] +
            metrics.get("reply_count", 0) * scoring["reply_weight"]
        )
        return score

    def _deduplicate(self):
        """é‡è¤‡æ’é™¤ï¼ˆURLåŸºæº–ï¼‰"""
        seen_urls = set()
        unique_items = []

        for item in self.items:
            if item.url not in seen_urls:
                seen_urls.add(item.url)
                unique_items.append(item)
            else:
                self.stats["duplicates_removed"] += 1

        self.items = unique_items


class SlackReporter:
    """Slackãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»æŠ•ç¨¿"""

    def __init__(self, webhook_url: str, config: Dict, items: List[Item], stats: Dict):
        self.webhook_url = webhook_url
        self.config = config
        self.items = items
        self.stats = stats

    def send(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦Slackã«æŠ•ç¨¿"""
        print("ğŸ“¤ Slackãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")

        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_items = sorted(self.items, key=lambda x: x.score, reverse=True)

        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘
        top_items = sorted_items[:self.config["slack"]["limits"]["top"]]
        provider_items = [i for i in sorted_items if i.source == "rss"][:self.config["slack"]["limits"]["provider_official"]]
        github_items = [i for i in sorted_items if i.source == "github"][:self.config["slack"]["limits"]["github_updates"]]

        # Slack Blocksæ§‹ç¯‰
        blocks = []

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        blocks.append({
            "type": "header",
            "text": {"type": "plain_text", "text": f"ğŸ¦ XæŠ•ç¨¿ç´ æ¡ˆ - {datetime.now().strftime('%Y-%m-%d')}"}
        })

        # XæŠ•ç¨¿ç´ æ¡ˆã‚’ç”Ÿæˆï¼ˆå€‹åˆ¥ã®ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦è¿½åŠ ï¼‰
        draft_blocks = self._generate_x_post_draft_blocks(top_items, provider_items, github_items)
        blocks.extend(draft_blocks)

        # é€ä¿¡
        payload = {"blocks": blocks}
        response = requests.post(self.webhook_url, json=payload)

        if response.status_code == 200:
            print("âœ… Slackã«æŠ•ç¨¿ã—ã¾ã—ãŸ")
        else:
            print(f"âŒ SlackæŠ•ç¨¿å¤±æ•—: {response.status_code} {response.text}")
            raise Exception("SlackæŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")

    def _generate_x_post_draft(self, top_items: List[Item], provider_items: List[Item], github_items: List[Item]) -> str:
        """XæŠ•ç¨¿ç´ æ¡ˆã‚’ç”Ÿæˆï¼ˆè¨˜äº‹ã”ã¨ã«å€‹åˆ¥æŠ•ç¨¿ã‚’ä½œæˆï¼‰"""
        drafts = []
        seen_urls = set()  # URLé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨
        today = datetime.now().strftime('%Y/%m/%d')

        # RSSï¼ˆå…¬å¼ç™ºè¡¨ï¼‰ã‚’å„ªå…ˆçš„ã«æŠ•ç¨¿ç´ æ¡ˆä½œæˆï¼ˆAnthropicãªã©ã®é‡è¦ãªå…¬å¼ç™ºè¡¨ã‚’ç¢ºå®Ÿã«å«ã‚ã‚‹ï¼‰
        for item in provider_items[:7]:  # 5â†’7ã«å¢—åŠ 
            if item.url in seen_urls:
                continue
            seen_urls.add(item.url)

            feed_name = item.metadata.get("feed_name", "")
            post = self._create_single_post(
                title=item.title,
                url=item.url,
                source_type="å…¬å¼ç™ºè¡¨",
                source_name=feed_name,
                date=today,
                item=item
            )
            drafts.append(f"ã€æŠ•ç¨¿æ¡ˆ {len(drafts) + 1}ã€‘\n{post}")

        # GitHub Releaseã¯å‰Šé™¤ï¼ˆRSSã§å–å¾—ã™ã‚‹ãŸã‚ä¸è¦ï¼‰

        # ãƒˆãƒƒãƒ—ãƒã‚¤ãƒ©ã‚¤ãƒˆã‹ã‚‰è¿½åŠ ï¼ˆ2â†’1ã«å‰Šæ¸›ï¼‰
        for item in top_items[:1]:
            if item.url in seen_urls:
                continue
            if item.source in ["rss", "github"]:
                continue  # æ—¢ã«è¿½åŠ æ¸ˆã¿

            seen_urls.add(item.url)

            source_name = item.metadata.get("username", "") or item.metadata.get("keyword", "")
            post = self._create_single_post(
                title=item.title,
                url=item.url,
                source_type="Xæ³¨ç›®æŠ•ç¨¿",
                source_name=source_name,
                date=today,
                item=item
            )
            drafts.append(f"ã€æŠ•ç¨¿æ¡ˆ {len(drafts) + 1}ã€‘\n{post}")

        return "\n\n" + ("-" * 50) + "\n\n".join(drafts) if drafts else ""

    def _generate_x_post_draft_blocks(self, top_items: List[Item], provider_items: List[Item], github_items: List[Item]) -> List[Dict]:
        """XæŠ•ç¨¿ç´ æ¡ˆã‚’Slack Blocksã¨ã—ã¦ç”Ÿæˆï¼ˆå„æŠ•ç¨¿ã‚’å€‹åˆ¥ãƒ–ãƒ­ãƒƒã‚¯ã«ï¼‰"""
        blocks = []
        seen_urls = set()
        today = datetime.now().strftime('%Y/%m/%d')
        draft_count = 0

        # RSSï¼ˆå…¬å¼ç™ºè¡¨ï¼‰ã‚’å„ªå…ˆçš„ã«æŠ•ç¨¿ç´ æ¡ˆä½œæˆ
        for item in provider_items[:7]:
            if item.url in seen_urls:
                continue
            seen_urls.add(item.url)
            draft_count += 1

            feed_name = item.metadata.get("feed_name", "")
            post = self._create_single_post(
                title=item.title,
                url=item.url,
                source_type="å…¬å¼ç™ºè¡¨",
                source_name=feed_name,
                date=today,
                item=item
            )

            # å„æŠ•ç¨¿ã‚’å€‹åˆ¥ã®sectionãƒ–ãƒ­ãƒƒã‚¯ã«ï¼ˆ3000æ–‡å­—åˆ¶é™å›é¿ï¼‰
            blocks.append({
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"```ã€æŠ•ç¨¿æ¡ˆ {draft_count}ã€‘\n{post}```"}
            })

            # åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ ï¼ˆæœ€å¾Œä»¥å¤–ï¼‰
            if draft_count < 7:
                blocks.append({"type": "divider"})

        # ãƒˆãƒƒãƒ—ãƒã‚¤ãƒ©ã‚¤ãƒˆã‹ã‚‰è¿½åŠ 
        for item in top_items[:1]:
            if item.url in seen_urls:
                continue
            if item.source in ["rss", "github"]:
                continue

            seen_urls.add(item.url)
            draft_count += 1

            source_name = item.metadata.get("username", "") or item.metadata.get("keyword", "")
            post = self._create_single_post(
                title=item.title,
                url=item.url,
                source_type="Xæ³¨ç›®æŠ•ç¨¿",
                source_name=source_name,
                date=today,
                item=item
            )

            blocks.append({
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"```ã€æŠ•ç¨¿æ¡ˆ {draft_count}ã€‘\n{post}```"}
            })

        return blocks

    def _create_single_post(self, title: str, url: str, source_type: str, source_name: str, date: str, item: Item) -> str:
        """å€‹åˆ¥ã®XæŠ•ç¨¿ã‚’ç”Ÿæˆ"""
        # Twitterã®URLã‚’x.comã«å¤‰æ›
        if "twitter.com" in url:
            url = url.replace("twitter.com", "x.com")

        # Claude API ã§ã‚µãƒãƒ©ã‚¤ã‚ºç”Ÿæˆï¼ˆPhase 1: ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
        summary = self._generate_summary_with_claude(title, url, source_type)

        return summary

    def _generate_summary_with_claude(self, title: str, url: str, source_type: str) -> str:
        """Claude API ã§é«˜å“è³ªãªXæŠ•ç¨¿ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ç”Ÿæˆ"""
        try:
            import anthropic

            api_key = os.environ.get("ANTHROPIC_API_KEY")
            if not api_key:
                print("âš ï¸  ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç°¡æ˜“è¦ç´„ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
                return self._generate_simple_summary(title, source_type, url)

            client = anthropic.Anthropic(api_key=api_key)

            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆå…±é€šï¼‰
            system_prompt = """ã‚ãªãŸã¯AIæ¥­ç•Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†Xï¼ˆTwitterï¼‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æŠ•ç¨¿ä½œæˆè€…ã§ã™ã€‚
èª­è€…ã¯AIã«é–¢å¿ƒã®ã‚ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ã‚„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚

ã€é‡è¦ãªåŸå‰‡ã€‘
- å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹
- èª­è€…ãŒã€Œè‡ªåˆ†ã‚‚ä½¿ã£ã¦ã¿ãŸã„ã€ã¨æ€ãˆã‚‹å†…å®¹ã«ã™ã‚‹
- æŠ½è±¡çš„ãªè¡¨ç¾ï¼ˆã€Œé©æ–°çš„ã€ã€Œç”»æœŸçš„ã€ï¼‰ã¯é¿ã‘ã€ä½•ãŒã§ãã‚‹ã‹ã‚’æ˜ç¤ºã™ã‚‹
- çµµæ–‡å­—ã¯æœ€å°é™ã«æŠ‘ãˆã‚‹
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç•ªå·ã¯ã€Œ1.ã€ã€Œ2.ã€ã€Œ3.ã€ã®å½¢å¼ã§æ§‹é€ åŒ–ã™ã‚‹"""

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_prompt = f"""ä»¥ä¸‹ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ã„ã¦ã€XæŠ•ç¨¿ã‚¹ãƒ¬ãƒƒãƒ‰ã®ç´ æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{title}

ã€ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã€‘
{source_type}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘

ã€é€Ÿå ±ã€‘ã¾ãŸã¯ã€æ³¨ç›®ã€‘ä¼æ¥­åã€ã€Œè£½å“/æ©Ÿèƒ½åã€ã‚’ç™ºè¡¨/ãƒªãƒªãƒ¼ã‚¹

[2-3æ–‡ã§æ ¸å¿ƒã‚’è¦ç´„ã€‚ä½•ãŒæ–°ã—ã„ã®ã‹ã€ãªãœé‡è¦ãªã®ã‹ã‚’æ˜ç¢ºã«]

{url}

1. [ã‚»ã‚¯ã‚·ãƒ§ãƒ³å]

ãƒ»å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ç‰¹å¾´1
ãƒ»å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ç‰¹å¾´2
ãƒ»å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ç‰¹å¾´3

[ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è£œè¶³èª¬æ˜ã‚’ä¸€æ–‡ã§]

2. [ã‚»ã‚¯ã‚·ãƒ§ãƒ³å]

ãƒ»å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ç‰¹å¾´4
ãƒ»å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„ç‰¹å¾´5

[ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è£œè¶³èª¬æ˜ã‚’ä¸€æ–‡ã§]

3. [åˆ©ç”¨æ–¹æ³•ãƒ»å¯¾è±¡è€…]

ãƒ»å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼: [å…·ä½“çš„ã«]
ãƒ»æä¾›é–‹å§‹: [ã„ã¤ã‹ã‚‰]
ãƒ»ä»Šå¾Œã®äºˆå®š: [ã‚ã‚Œã°]

ã€é‡è¦ãªåˆ¶ç´„ã€‘
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç®‡æ¡æ›¸ãã¯3-5é …ç›®
- ç®‡æ¡æ›¸ãã«ã¯ã€Œãƒ»ã€ï¼ˆä¸­é»’ï¼‰ã®ã¿ä½¿ç”¨
- â– ã€â–¸ã€ğŸ’¡ã€ğŸ”— ãªã©ã®è£…é£¾è¨˜å·ã¯ä¸è¦
- URLã¯å†’é ­ã®è¦ç´„ã®ç›´å¾Œã«é…ç½®
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç•ªå·ã¯ã€Œ1.ã€ã€Œ2.ã€ã€Œ3.ã€ã®å½¢å¼ã§æ§‹é€ åŒ–
- å…¨ä½“ã§600-800æ–‡å­—ç¨‹åº¦ï¼ˆXã‚¹ãƒ¬ãƒƒãƒ‰ã¨ã—ã¦é©åˆ‡ãªé•·ã•ï¼‰
- ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¨æ¸¬ã—ã¦å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„"""

            message = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=1500,  # 800æ–‡å­—è¦æ±‚ãªã®ã§ä½™è£•ã‚’æŒãŸã›ã‚‹
                system=system_prompt,  # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¿½åŠ 
                messages=[{
                    "role": "user",
                    "content": user_prompt
                }]
            )

            return message.content[0].text

        except Exception as e:
            print(f"âš ï¸ Claude API ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“è¦ç´„
            return self._generate_simple_summary(title, source_type, url)

    def _generate_simple_summary(self, title: str, source_type: str, url: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡æ˜“è¦ç´„"""
        if source_type == "å…¬å¼ç™ºè¡¨":
            emoji = "ğŸš€"
            comment = "é‡è¦ãªå…¬å¼ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ã§ã™"
        elif source_type == "GitHub Release":
            emoji = "ğŸ“¦"
            comment = "æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸ"
        else:
            emoji = "ğŸ’¡"
            comment = "æ³¨ç›®ã®è©±é¡Œã§ã™"

        # ç°¡æ½”ãªå½¢å¼
        lines = [
            f"ã€{emoji} {title[:60]}{'...' if len(title) > 60 else ''}ã€‘",
            "",
            f"ğŸ’¡ {comment}ã€‚è©³ç´°ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ã‚‡ã†ã€‚",
            "",
            f"ğŸ”— {url}"
        ]

        return "\n".join(lines)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("AIãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ")
    print("=" * 60)

    # è¨­å®šèª­ã¿è¾¼ã¿
    with open("config.yaml", 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    x_bearer_token = os.environ.get("X_BEARER_TOKEN")
    slack_webhook_url = os.environ.get("SLACK_WEBHOOK_URL")

    if not x_bearer_token:
        raise ValueError("ç’°å¢ƒå¤‰æ•° X_BEARER_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    if not slack_webhook_url:
        raise ValueError("ç’°å¢ƒå¤‰æ•° SLACK_WEBHOOK_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # åˆæœŸåŒ–
    state = StateManager()
    x_client = XAPIClient(x_bearer_token)
    collector = DataCollector(config, state, x_client)

    try:
        # ãƒ‡ãƒ¼ã‚¿åé›†
        collector.collect_all()

        # Slackãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
        reporter = SlackReporter(slack_webhook_url, config, collector.items, collector.stats)
        reporter.send()

        # çŠ¶æ…‹ä¿å­˜ï¼ˆæœ€å¾Œã«å®Ÿè¡Œï¼‰
        state.save()
        print("ğŸ’¾ çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

    print("=" * 60)
    print("âœ… å®Œäº†")
    print("=" * 60)


if __name__ == "__main__":
    main()
