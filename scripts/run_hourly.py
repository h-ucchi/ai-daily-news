#!/usr/bin/env python3
"""
AI Semi-Daily Report - 8æ™‚ã¨15æ™‚ã®change logèª¿æŸ»ã¨XæŠ•ç¨¿ä¸‹æ›¸ãç”Ÿæˆ

ä½¿ã„æ–¹:
  python scripts/run_hourly.py
"""

import os
import sys
import hashlib
import requests
from pathlib import Path
from datetime import datetime, timezone
from dataclasses import asdict, dataclass
from typing import List, Dict, Optional
import yaml

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from run_daily import (
    XAPIClient, StateManager, DataCollector, SlackReporter
)
from draft_manager import DraftManager
from content_validator import ContentValidator


@dataclass
class PageSnapshot:
    """ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    url: str
    name: str
    content_hash: str
    content: str
    timestamp: str


class SnapshotManager:
    """ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç®¡ç†"""

    def __init__(self, snapshots_dir: str = "data/snapshots"):
        self.snapshots_dir = Path(snapshots_dir)
        self.snapshots_dir.mkdir(parents=True, exist_ok=True)

    def _get_snapshot_path(self, url: str) -> Path:
        """URLã‹ã‚‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        url_hash = hashlib.md5(url.encode()).hexdigest()
        return self.snapshots_dir / f"{url_hash}.txt"

    def fetch_page_content(self, url: str) -> str:
        """ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—"""
        headers = {
            "User-Agent": "Mozilla/5.0 (compatible; AIResearchBot/1.0)"
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        return response.text

    def save_snapshot(self, snapshot: PageSnapshot):
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜"""
        snapshot_path = self._get_snapshot_path(snapshot.url)
        with open(snapshot_path, 'w', encoding='utf-8') as f:
            f.write(f"# {snapshot.name}\n")
            f.write(f"# URL: {snapshot.url}\n")
            f.write(f"# Timestamp: {snapshot.timestamp}\n")
            f.write(f"# Hash: {snapshot.content_hash}\n")
            f.write("\n")
            f.write(snapshot.content)

    def load_snapshot(self, url: str) -> Optional[PageSnapshot]:
        """ä¿å­˜æ¸ˆã¿ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿"""
        snapshot_path = self._get_snapshot_path(url)
        if not snapshot_path.exists():
            return None

        with open(snapshot_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            if len(lines) < 5:
                return None

            name = lines[0].replace("# ", "").strip()
            url_line = lines[1].replace("# URL: ", "").strip()
            timestamp = lines[2].replace("# Timestamp: ", "").strip()
            content_hash = lines[3].replace("# Hash: ", "").strip()
            content = "".join(lines[5:])

            return PageSnapshot(
                url=url_line,
                name=name,
                content_hash=content_hash,
                content=content,
                timestamp=timestamp
            )

    def check_for_changes(self, url: str, name: str) -> Optional[PageSnapshot]:
        """ãƒšãƒ¼ã‚¸ã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå‰å›åˆ†ã®ã¿ä¿æŒï¼‰"""
        try:
            # æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            new_content = self.fetch_page_content(url)
            new_hash = hashlib.sha256(new_content.encode()).hexdigest()

            # å‰å›ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿
            old_snapshot = self.load_snapshot(url)

            # åˆå›ã¾ãŸã¯å¤‰æ›´ã‚ã‚Š
            if old_snapshot is None or old_snapshot.content_hash != new_hash:
                new_snapshot = PageSnapshot(
                    url=url,
                    name=name,
                    content_hash=new_hash,
                    content=new_content,
                    timestamp=datetime.now(timezone.utc).isoformat()
                )
                # å‰å›ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¸Šæ›¸ãï¼ˆç´¯ç©ä¿å­˜ã—ãªã„ï¼‰
                self.save_snapshot(new_snapshot)

                if old_snapshot is None:
                    print(f"ğŸ“¸ åˆå›ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: {name}")
                    return None  # åˆå›ã¯å¤‰æ›´ã¨ã—ã¦æ‰±ã‚ãªã„
                else:
                    print(f"ğŸ”„ å¤‰æ›´æ¤œå‡º: {name}")
                    return new_snapshot
            else:
                # å¤‰æ›´ãŒãªã„å ´åˆã‚‚æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ä¸Šæ›¸ã
                # ï¼ˆå‰å›ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’æœ€æ–°ã«ä¿ã¤ï¼‰
                new_snapshot = PageSnapshot(
                    url=url,
                    name=name,
                    content_hash=new_hash,
                    content=new_content,
                    timestamp=datetime.now(timezone.utc).isoformat()
                )
                self.save_snapshot(new_snapshot)
                print(f"âœ… å¤‰æ›´ãªã—: {name}")
                return None

        except Exception as e:
            print(f"âŒ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—å¤±æ•—: {name} - {e}")
            return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("AI Semi-Dailyãƒ¬ãƒãƒ¼ãƒˆ - 8æ™‚ãƒ»15æ™‚ã®change logèª¿æŸ»")
    print("=" * 60)

    # è¨­å®šèª­ã¿è¾¼ã¿
    with open("config.yaml", 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # ç’°å¢ƒå¤‰æ•°å–å¾—
    x_bearer_token = os.environ.get("X_BEARER_TOKEN")
    slack_webhook_url = os.environ.get("SLACK_WEBHOOK_URL")

    if not x_bearer_token:
        raise ValueError("ç’°å¢ƒå¤‰æ•° X_BEARER_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    if not slack_webhook_url:
        raise ValueError("ç’°å¢ƒå¤‰æ•° SLACK_WEBHOOK_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # OAuthèªè¨¼æƒ…å ±ã®å–å¾—ï¼ˆX APIæŠ•ç¨¿ç”¨ï¼‰
    oauth_credentials = None
    if all([
        os.environ.get("X_API_KEY"),
        os.environ.get("X_API_SECRET"),
        os.environ.get("X_ACCESS_TOKEN"),
        os.environ.get("X_ACCESS_TOKEN_SECRET")
    ]):
        oauth_credentials = {
            "api_key": os.environ.get("X_API_KEY"),
            "api_secret": os.environ.get("X_API_SECRET"),
            "access_token": os.environ.get("X_ACCESS_TOKEN"),
            "access_token_secret": os.environ.get("X_ACCESS_TOKEN_SECRET")
        }

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    x_client = XAPIClient(x_bearer_token, oauth_credentials)
    state = StateManager("data/state_hourly.json")  # semi-dailyå°‚ç”¨ã®state
    collector = DataCollector(config, state, x_client)

    try:
        # ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç›£è¦–
        print("\nğŸ“¸ ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç›£è¦–é–‹å§‹")
        snapshot_manager = SnapshotManager()

        # ç›£è¦–å¯¾è±¡ãƒšãƒ¼ã‚¸ã‚’config.yamlã‹ã‚‰èª­ã¿è¾¼ã¿
        page_config = config.get("page_monitoring", {})
        if not page_config.get("enabled", True):
            print("ğŸ“¸ ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç›£è¦–ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
            snapshot_changes = []
        else:
            pages_to_monitor = page_config.get("pages", [])
            print(f"ğŸ“¸ ãƒšãƒ¼ã‚¸ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç›£è¦–é–‹å§‹: {len(pages_to_monitor)}ãƒšãƒ¼ã‚¸")

            snapshot_changes = []
            for page in pages_to_monitor:
                changed_snapshot = snapshot_manager.check_for_changes(
                    page["url"],
                    page["name"]
                )
                if changed_snapshot:
                    snapshot_changes.append(changed_snapshot)

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå¤‰æ›´ãŒã‚ã‚Œã°Slackã«é€šçŸ¥
        if snapshot_changes:
            print(f"\nğŸ”” {len(snapshot_changes)}ä»¶ã®ãƒšãƒ¼ã‚¸å¤‰æ›´ã‚’æ¤œå‡º")
            # TODO: Slacké€šçŸ¥ã‚’å®Ÿè£…ï¼ˆå¾Œã»ã©ï¼‰

        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿åé›†
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        collector.collect_all()

        # æ›´æ–°ãŒãªã„å ´åˆã¯æ—©æœŸçµ‚äº†
        if not collector.items and not snapshot_changes:
            print("âœ… æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“")
            state.save()
            return

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        new_items = []
        for item in collector.items:
            if not state.is_recently_posted(item.url):
                new_items.append(item)
            else:
                print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ24æ™‚é–“ä»¥å†…ã«æŠ•ç¨¿æ¸ˆã¿ï¼‰: {item.url}")

        if not new_items and not snapshot_changes:
            print("âœ… æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆå…¨ã¦æŠ•ç¨¿æ¸ˆã¿ï¼‰")
            state.save()
            return

        collector.items = new_items

        # Slackãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡
        if collector.items:
            reporter = SlackReporter(
                slack_webhook_url,
                config,
                collector.items,
                collector.stats
            )
            reporter.send()

        # ä¸‹æ›¸ãç®¡ç†
        draft_manager = DraftManager()
        validator = ContentValidator(config)  # æ¤œè¨¼å™¨åˆæœŸåŒ–

        # ä¸Šä½3ä»¶ã‚’ä¸‹æ›¸ãã¨ã—ã¦ä¿å­˜
        for item in collector.items[:3]:
            post_text = reporter._create_single_post(
                title=item.title,
                url=item.url,
                source_type=item.source,
                source_name=item.metadata.get("feed_name", ""),
                date=datetime.now().strftime('%Y/%m/%d'),
                item=item
            )

            # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º1: æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹
            if post_text is None:
                print(f"â­ï¸  ä¸‹æ›¸ãã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ¤œè¨¼å¤±æ•—ï¼‰: {item.title[:50]}...")
                continue

            validation_result = validator.validate_post(post_text, item.title)
            if not validation_result.is_valid:
                print(f"â­ï¸  ä¸‹æ›¸ãã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ¤œè¨¼å¤±æ•—ï¼‰: {item.title[:50]}...")
                print(f"    ç†ç”±: {validation_result.rejection_reason}")
                continue

            # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º2: Claude APIãƒ¬ãƒ“ãƒ¥ãƒ¼
            review_result = validator.review_post_with_claude(post_text, item.title, item.url)
            if not review_result.is_valid:
                print(f"â­ï¸  ä¸‹æ›¸ãã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å¤±æ•—ï¼‰: {item.title[:50]}...")
                print(f"    ç†ç”±: {review_result.rejection_reason}")
                continue

            draft_id = draft_manager.save_draft(asdict(item), post_text)
            print(f"ğŸ“ ä¸‹æ›¸ãä¿å­˜: {draft_id} - {item.title[:50]}...")

            # æŠ•ç¨¿æ¸ˆã¿ã«ãƒãƒ¼ã‚¯
            state.mark_as_posted(item.url)

        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå¤‰æ›´ã‚‚ä¸‹æ›¸ãã¨ã—ã¦ä¿å­˜
        for snapshot in snapshot_changes:
            # ç°¡æ˜“çš„ãªæŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            post_text = f"{snapshot.name}ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ\n\n{snapshot.url}\n\n{datetime.now().strftime('%Y/%m/%d')}"
            draft_id = draft_manager.save_draft(
                {
                    "title": f"{snapshot.name} æ›´æ–°",
                    "url": snapshot.url,
                    "source": "snapshot",
                    "metadata": {"snapshot": True}
                },
                post_text
            )
            print(f"ğŸ“ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå¤‰æ›´ã‚’ä¸‹æ›¸ãä¿å­˜: {draft_id}")

        # å¤ã„å±¥æ­´ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        state.cleanup_old_posted_urls()

        # çŠ¶æ…‹ä¿å­˜
        state.save()
        print("ğŸ’¾ çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

    print("=" * 60)
    print("âœ… å‡¦ç†å®Œäº†")
    print("=" * 60)


if __name__ == "__main__":
    main()
